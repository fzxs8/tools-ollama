# 哆啦桌面端 - 用户指南

欢迎使用哆啦桌面端！本指南将帮助您了解并充分利用其各项强大功能。

## 目录
1.  [初次设置：配置Ollama服务](#1-初次设置配置ollama服务)
2.  [核心功能](#2-核心功能)
    *   [会话管理 (Chat Manager)](#会话管理-chat-manager)
    *   [模型管理 (Model Manager)](#模型管理-model-manager)
    *   [模型市场 (Model Market)](#模型市场-model-market)
    *   [提示词工程 (Prompt Engineering)](#提示词工程-prompt-engineering)
    *   [OpenAI 适配器](#openai-适配器)
    *   [API 调试器](#api-调试器)

---

### 1. 初次设置：配置Ollama服务

在使用任何AI功能之前，您需要先配置Ollama服务。

1.  前往 **服务设置 (Ollama Settings)** 页面。
2.  系统会自动检测本地服务。如果您的Ollama在本地运行，通常无需额外配置。
3.  点击 **“添加服务”** 来配置一个远程Ollama服务器。
4.  填写 **名称** 和 **服务地址** (例如 `http://192.168.1.10:11434`)。
5.  您可以通过 **“测试”** 按钮检查连接是否成功。
6.  通过操作菜单的 **“设置默认”**，可以指定一个服务作为所有功能的默认选项。

### 2. 核心功能

#### 会话管理 (Chat Manager)

这是您与AI模型进行交互式对话的主要界面。

-   **模型选择**: 在左侧边栏，您可以选择当前对话所使用的服务器和模型。
-   **参数调整**: 您可以调整模型的温度、Top-P等参数，以控制生成内容的多样性。
-   **流式对话**: 对话内容会以打字机的效果实时显示，提供流畅的体验。
-   **对话历史**:
    -   所有对话都会自动保存。
    -   点击右上角的历史记录按钮，可以加载、编辑或删除之前的对话。
-   **系统提示词**: 您可以从提示词工程模块选择一个系统提示词，为AI设定角色或提供背景信息。

#### 模型管理 (Model Manager)

管理您所有Ollama服务上的本地模型。

-   **多服务器管理**: 通过顶部的下拉菜单，轻松切换不同的Ollama服务器，查看其下的模型。
-   **模型列表**: 以表格形式清晰展示模型的名称、大小、修改时间和运行状态。
-   **运行/停止模型**: 在模型详情中，您可以一键启动或停止一个模型。
-   **下载新模型**:
    -   点击“下载模型”按钮，输入模型名称（如 `llama3`）即可开始下载。
    -   通过“下载队列”可以实时查看下载进度。
-   **测试模型**: 在模型详情中，提供了一个测试区域，您可以输入任意内容快速测试模型响应。
-   **删除模型**: 您可以删除不再需要的本地模型。

#### 模型市场 (Model Market)

发现来自 `ollama.com/library` 的海量在线模型。

-   **浏览与搜索**: 页面默认展示热门模型，您也可以通过顶部的搜索框查找特定模型。
-   **查看详情**: 点击“详情”可以查看模型的详细信息，包括下载次数、更新时间等。
-   **直接下载**: （此功能在模型管理中实现）您可以在模型市场找到心仪的模型后，复制其名称到模型管理页面进行下载。

#### 提示词工程 (Prompt Engineering)

一个强大的工具，用于创建、测试和优化您的提示词。

-   **并行生成**: 输入您的核心“想法”，然后选择多个模型（最多3个），系统将并行生成不同风格的提示词。
-   **结果对比**: 在右侧的结果区，通过标签页轻松切换和对比不同模型的生成结果。
-   **重新生成**: 对某个模型的结果不满意？可以单独对其进行“重新生成”。
-   **保存与管理**:
    -   满意的结果可以一键“保存”。
    -   通过“管理”面板，您可以查看、搜索、编辑和删除所有已保存的提示词。

#### OpenAI 适配器

将您的本地Ollama服务转换为一个兼容OpenAI API的接口，让更多第三方应用（如LobeChat）可以无缝接入。

1.  前往 **OpenAI 适配器** 页面。
2.  **配置**: 设置服务监听的IP和端口，并选择一个要代理的目标Ollama服务。
3.  **启动**: 点击“启动服务”开关。
4.  **使用**: 服务启动后，您就可以在其他应用中填入 `http://<您设置的IP>:<您设置的端口>` 作为OpenAI API地址来使用了。
5.  **实时日志**: 通过“查看日志”抽屉，可以实时监控所有API请求和响应。
6.  **API文档与调试**: “查看API”抽屉不仅提供了`curl`调用示例，还内置了一个API调试器，让您直接在应用内测试接口。

#### API 调试器

一个类似Postman的专业工具，专门用于调试Ollama的原生API。

-   **预设接口**: 左侧列表预设了所有Ollama官方API，点击即可自动填充所有参数。
-   **完全自定义**: 您可以修改URL、请求方法、查询参数、请求头和请求体。
-   **发送与查看**: 点击“发送”后，在下方响应区可以清晰地看到格式化后的响应体、响应头、状态码和请求耗时。
